{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlJowqnKBxWT",
        "outputId": "2a776828-7ba9-4c64-a493-f3d4cdeb3e2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/116.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m112.6/116.9 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.9/116.9 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/129.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.3/129.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.4/100.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -Uq openai-agents"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "axIOlJ4aB4Oz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "MODEL = 'gemini-2.0-flash'"
      ],
      "metadata": {
        "id": "US9aoMPLB61g"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "from openai import AsyncOpenAI\n",
        "from agents import Agent, OpenAIChatCompletionsModel, Runner, set_tracing_disabled, enable_verbose_stdout_logging\n",
        "\n",
        "# Debug Mode enable code\n",
        "enable_verbose_stdout_logging();\n",
        "\n",
        "external_client = AsyncOpenAI(\n",
        "    api_key=API_KEY,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\",\n",
        ")\n",
        "set_tracing_disabled(disabled=True)"
      ],
      "metadata": {
        "id": "B9f8Ei5HB-PY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "web_developer = Agent(\n",
        "        name=\"Web Developer Agent\",\n",
        "        instructions=\"You are a professional Web Developer.\",\n",
        "        model=OpenAIChatCompletionsModel(model=MODEL, openai_client=external_client),\n",
        "    )"
      ],
      "metadata": {
        "id": "PeYjYxAcCELz"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "app_developer = Agent(\n",
        "        name=\"Mobile App Developer Agent\",\n",
        "        instructions=\"You are a professional Mobile App Developer.\",\n",
        "        model=OpenAIChatCompletionsModel(model=MODEL, openai_client=external_client),\n",
        "    )"
      ],
      "metadata": {
        "id": "J_HLhvBICKwK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ai_agent_be_dev_agent = Agent(\n",
        "    name=\"Back-end Dev AI Agent\",\n",
        "     instructions=\"You are a professional AI Agent Back-end Work.\",\n",
        ")\n",
        "\n",
        "# Define a support agent\n",
        "ai_agent_devops_agent = Agent(\n",
        "    name=\"DevOps Dev AI Agent\",\n",
        "    instructions=\"You are a professional AI Agent for DevOps Work.\",\n",
        ")\n"
      ],
      "metadata": {
        "id": "ZyLkOqBRCPfN"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert agents into tools\n",
        "ai_agent_be_dev_agent_tool = ai_agent_be_dev_agent.as_tool(\n",
        "            tool_name=\"ai_agent_be_dev_agent_tool\",\n",
        "            tool_description=\"Assistant to provide BE suport for agentic ai development\",)\n",
        "\n",
        "ai_agent_devops_agent_tool = ai_agent_devops_agent.as_tool(\n",
        "            tool_name=\"ai_agent_devops_agent_tool\",\n",
        "            tool_description=\"Assistant to provide DevOps suport for agentic ai development\",)"
      ],
      "metadata": {
        "id": "7Y-f5uz-Ddiv"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ai_agent = Agent(\n",
        "        name=\"AI Agent\",\n",
        "        instructions=\"You are a professional AI AGent.\",\n",
        "        model=OpenAIChatCompletionsModel(model=MODEL, openai_client=external_client),\n",
        "        tools=[ai_agent_be_dev_agent_tool, ai_agent_devops_agent_tool]\n",
        "    )"
      ],
      "metadata": {
        "id": "mEHIT7R4DRhn"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "personal_agent = Agent(\n",
        "        name=\"Personal Agent\",\n",
        "        instructions=\"You determine which agent should handle the user's request based on the nature of the inquiry.\",\n",
        "        model=OpenAIChatCompletionsModel(model=MODEL, openai_client=external_client),\n",
        "        handoffs=[web_developer, app_developer, ai_agent]\n",
        "    )"
      ],
      "metadata": {
        "id": "cPMoezj5EoyE"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = Runner.run_sync(personal_agent, \"What is html is used for? and where?\")\n",
        "print(result.last_agent)\n",
        "# print(result.final_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cN_9LmdXE2gA",
        "outputId": "cd61b5fd-6082-454c-a763-038e204f2917"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tracing is disabled. Not creating trace Agent workflow\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:Tracing is disabled. Not creating trace Agent workflow\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting current trace: no-op\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:Setting current trace: no-op\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tracing is disabled. Not creating span <agents.tracing.span_data.AgentSpanData object at 0x7922cfedc710>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:Tracing is disabled. Not creating span <agents.tracing.span_data.AgentSpanData object at 0x7922cfedc710>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running agent Personal Agent (turn 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:Running agent Personal Agent (turn 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tracing is disabled. Not creating span <agents.tracing.span_data.GenerationSpanData object at 0x7922cfedc770>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:Tracing is disabled. Not creating span <agents.tracing.span_data.GenerationSpanData object at 0x7922cfedc770>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "  {\n",
            "    \"content\": \"You determine which agent should handle the user's request based on the nature of the inquiry.\",\n",
            "    \"role\": \"system\"\n",
            "  },\n",
            "  {\n",
            "    \"role\": \"user\",\n",
            "    \"content\": \"What is html is used for? and where?\"\n",
            "  }\n",
            "]\n",
            "Tools:\n",
            "[\n",
            "  {\n",
            "    \"type\": \"function\",\n",
            "    \"function\": {\n",
            "      \"name\": \"transfer_to_web_developer_agent\",\n",
            "      \"description\": \"Handoff to the Web Developer Agent agent to handle the request. \",\n",
            "      \"parameters\": {\n",
            "        \"additionalProperties\": false,\n",
            "        \"type\": \"object\",\n",
            "        \"properties\": {},\n",
            "        \"required\": []\n",
            "      }\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"function\",\n",
            "    \"function\": {\n",
            "      \"name\": \"transfer_to_mobile_app_developer_agent\",\n",
            "      \"description\": \"Handoff to the Mobile App Developer Agent agent to handle the request. \",\n",
            "      \"parameters\": {\n",
            "        \"additionalProperties\": false,\n",
            "        \"type\": \"object\",\n",
            "        \"properties\": {},\n",
            "        \"required\": []\n",
            "      }\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"function\",\n",
            "    \"function\": {\n",
            "      \"name\": \"transfer_to_ai_agent\",\n",
            "      \"description\": \"Handoff to the AI Agent agent to handle the request. \",\n",
            "      \"parameters\": {\n",
            "        \"additionalProperties\": false,\n",
            "        \"type\": \"object\",\n",
            "        \"properties\": {},\n",
            "        \"required\": []\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "]\n",
            "Stream: False\n",
            "Tool choice: NOT_GIVEN\n",
            "Response format: NOT_GIVEN\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:[\n",
            "  {\n",
            "    \"content\": \"You determine which agent should handle the user's request based on the nature of the inquiry.\",\n",
            "    \"role\": \"system\"\n",
            "  },\n",
            "  {\n",
            "    \"role\": \"user\",\n",
            "    \"content\": \"What is html is used for? and where?\"\n",
            "  }\n",
            "]\n",
            "Tools:\n",
            "[\n",
            "  {\n",
            "    \"type\": \"function\",\n",
            "    \"function\": {\n",
            "      \"name\": \"transfer_to_web_developer_agent\",\n",
            "      \"description\": \"Handoff to the Web Developer Agent agent to handle the request. \",\n",
            "      \"parameters\": {\n",
            "        \"additionalProperties\": false,\n",
            "        \"type\": \"object\",\n",
            "        \"properties\": {},\n",
            "        \"required\": []\n",
            "      }\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"function\",\n",
            "    \"function\": {\n",
            "      \"name\": \"transfer_to_mobile_app_developer_agent\",\n",
            "      \"description\": \"Handoff to the Mobile App Developer Agent agent to handle the request. \",\n",
            "      \"parameters\": {\n",
            "        \"additionalProperties\": false,\n",
            "        \"type\": \"object\",\n",
            "        \"properties\": {},\n",
            "        \"required\": []\n",
            "      }\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"function\",\n",
            "    \"function\": {\n",
            "      \"name\": \"transfer_to_ai_agent\",\n",
            "      \"description\": \"Handoff to the AI Agent agent to handle the request. \",\n",
            "      \"parameters\": {\n",
            "        \"additionalProperties\": false,\n",
            "        \"type\": \"object\",\n",
            "        \"properties\": {},\n",
            "        \"required\": []\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "]\n",
            "Stream: False\n",
            "Tool choice: NOT_GIVEN\n",
            "Response format: NOT_GIVEN\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLM resp:\n",
            "{\n",
            "  \"content\": \"HTML is the standard markup language for creating web pages. It provides the structure and content of a website, using elements to define headings, paragraphs, images, links, and more. It's used universally by web developers to build websites and web applications.\\n\\nWould you like me to transfer you to a Web Developer Agent for more details?\\n\",\n",
            "  \"refusal\": null,\n",
            "  \"role\": \"assistant\",\n",
            "  \"annotations\": null,\n",
            "  \"audio\": null,\n",
            "  \"function_call\": null,\n",
            "  \"tool_calls\": null\n",
            "}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:LLM resp:\n",
            "{\n",
            "  \"content\": \"HTML is the standard markup language for creating web pages. It provides the structure and content of a website, using elements to define headings, paragraphs, images, links, and more. It's used universally by web developers to build websites and web applications.\\n\\nWould you like me to transfer you to a Web Developer Agent for more details?\\n\",\n",
            "  \"refusal\": null,\n",
            "  \"role\": \"assistant\",\n",
            "  \"annotations\": null,\n",
            "  \"audio\": null,\n",
            "  \"function_call\": null,\n",
            "  \"tool_calls\": null\n",
            "}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resetting current trace\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:openai.agents:Resetting current trace\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Agent(name='Personal Agent', instructions=\"You determine which agent should handle the user's request based on the nature of the inquiry.\", handoff_description=None, handoffs=[Agent(name='Web Developer Agent', instructions='You are a professional Web Developer.', handoff_description=None, handoffs=[], model=<agents.models.openai_chatcompletions.OpenAIChatCompletionsModel object at 0x7922cfce6310>, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None), tools=[], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), Agent(name='Mobile App Developer Agent', instructions='You are a professional Mobile App Developer.', handoff_description=None, handoffs=[], model=<agents.models.openai_chatcompletions.OpenAIChatCompletionsModel object at 0x7922cfce54d0>, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None), tools=[], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), Agent(name='AI Agent', instructions='You are a professional AI AGent.', handoff_description=None, handoffs=[], model=<agents.models.openai_chatcompletions.OpenAIChatCompletionsModel object at 0x7922cfce60d0>, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None), tools=[FunctionTool(name='ai_agent_be_dev_agent_tool', description='Assistant to provide BE suport for agentic ai development', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'ai_agent_be_dev_agent_tool_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x7922cfce22a0>, strict_json_schema=True), FunctionTool(name='ai_agent_devops_agent_tool', description='Assistant to provide DevOps suport for agentic ai development', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'ai_agent_devops_agent_tool_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x7922f9e63100>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True)], model=<agents.models.openai_chatcompletions.OpenAIChatCompletionsModel object at 0x7922cfcf54d0>, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None), tools=[], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True)\n"
          ]
        }
      ]
    }
  ]
}