{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6aPMawBFxdO",
        "outputId": "cd08ac03-4d11-4f80-87eb-a95c17e73c9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/116.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.9/116.9 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/129.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.3/129.3 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/119.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.5/119.5 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -Uq openai-agents"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "MQz8uLDnF4vn"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "API_KEY = userdata.get('GOOGLE_API_KEY');\n",
        "MODEL = \"gemini-2.0-flash\";\n",
        "GEMINI_BASE_URL= \"https://generativelanguage.googleapis.com/v1beta/openai/\";"
      ],
      "metadata": {
        "id": "iangsrMrF4yv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent, Runner, OpenAIChatCompletionsModel, AsyncOpenAI, function_tool, ItemHelpers"
      ],
      "metadata": {
        "id": "ak2WN79KF41X"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "external_client = AsyncOpenAI(api_key=API_KEY, base_url=GEMINI_BASE_URL)"
      ],
      "metadata": {
        "id": "LePygyI3F439"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_completion_model = OpenAIChatCompletionsModel(openai_client=external_client, model=MODEL)"
      ],
      "metadata": {
        "id": "pSEV1WTjF46U"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import set_default_openai_client, set_default_openai_api, set_tracing_disabled\n",
        "\n",
        "set_default_openai_client(client=external_client, use_for_tracing=False)\n",
        "set_default_openai_api(\"chat_completions\")\n",
        "set_tracing_disabled(disabled=True)"
      ],
      "metadata": {
        "id": "qvwAg4MqGCFj"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "@function_tool\n",
        "def how_many_jokes(num) -> int:\n",
        "    return random.randint(1, 10)\n"
      ],
      "metadata": {
        "id": "fJzxttmfGIb8"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from openai.types.responses import ResponseTextDeltaEvent\n",
        "import asyncio\n",
        "\n",
        "@function_tool\n",
        "def how_many_jokes(num: int, type = 'Software Developer') -> int:\n",
        "    return random.randint(1, num)\n",
        "\n",
        "async def main():\n",
        "    agent = Agent(\n",
        "        name=\"Joker\",\n",
        "        instructions=(\n",
        "            \"Call the `how_many_jokes` tool with a number as a parameter. \"\n",
        "            \"Provide the number of jokes specified in the input.\"\n",
        "        ),\n",
        "        tools=[how_many_jokes],\n",
        "        model=chat_completion_model\n",
        "    )\n",
        "    runner = Runner.run_streamed(starting_agent=agent, input=\"I want 5 jokes.\")\n",
        "\n",
        "    async for event in runner.stream_events():\n",
        "        if event.type == \"run_item_stream_event\":\n",
        "            if event.item.type == \"tool_call_output_item\":\n",
        "\n",
        "                for tool in event.item.agent.tools:\n",
        "                    print(f\"-- Tool Name: {tool.name}\")\n",
        "                    # Extract and display all parameters of the tool\n",
        "                    if hasattr(tool, 'params_json_schema') and 'properties' in tool.params_json_schema:\n",
        "                        for param_name, param_details in tool.params_json_schema['properties'].items():\n",
        "                            print(f\"--- Parameter Name: {param_name}\")\n",
        "                            print(f\"--- Parameter Details: {param_details}\")\n",
        "                    else:\n",
        "                        print(\"--- No Parameters Found\")\n"
      ],
      "metadata": {
        "id": "j3vC8TMRGEJD"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the main function\n",
        "asyncio.run(main())"
      ],
      "metadata": {
        "id": "37XMu0M_Q5_7",
        "outputId": "7ef4b832-d503-4b4a-ecda-45cb78850fda",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Tool Name: how_many_jokes\n",
            "--- Parameter Name: num\n",
            "--- Parameter Details: {'title': 'Num', 'type': 'integer'}\n",
            "--- Parameter Name: type\n",
            "--- Parameter Details: {'default': 'Software Developer', 'title': 'Type'}\n"
          ]
        }
      ]
    }
  ]
}